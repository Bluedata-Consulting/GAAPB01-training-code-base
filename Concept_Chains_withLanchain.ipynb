{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac39c447",
   "metadata": {},
   "source": [
    "# Working with Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37b07328",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install langchain langchain-experimental langchain-openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f95fe1",
   "metadata": {},
   "source": [
    "### Chatmodels, Pormpt Templates and Parsers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9a074a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Why did the mouse stay home from school?\\n\\nBecause it was afraid of the cat-astrophe!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 13, 'total_tokens': 34, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini', 'system_fingerprint': 'fp_7a53abb7a2', 'id': 'chatcmpl-BWxmfEwTiShwuqV4jR0cuLVvVReK9', 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}, id='run-9d3c22ec-6e8f-4ea4-9475-cf531e052a9e-0', usage_metadata={'input_tokens': 13, 'output_tokens': 21, 'total_tokens': 34, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import AzureChatOpenAI\n",
    "\n",
    "model = AzureChatOpenAI(api_version=\"2024-12-01-preview\",model='telcogpt')\n",
    "\n",
    "prompt = \"Tell me a joke about mouse\"\n",
    "model.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "442c3b76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['language', 'text'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['language'], input_types={}, partial_variables={}, template='Translate the following into {language}'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['text'], input_types={}, partial_variables={}, template='{text}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "system_template = \"Translate the following into {language}\"\n",
    "\n",
    "prompt = ChatPromptTemplate([(\"system\",system_template),(\"user\",\"{text}\")])\n",
    "\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46c82c3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['language', 'text']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.input_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b44216ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='Translate the following into hindi', additional_kwargs={}, response_metadata={}), HumanMessage(content='HOW ARE YOU?', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.invoke({\"language\":\"hindi\",\"text\":\"HOW ARE YOU?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b3247dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='आप कैसे हैं?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 5, 'prompt_tokens': 20, 'total_tokens': 25, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini', 'system_fingerprint': 'fp_7a53abb7a2', 'id': 'chatcmpl-BWxneoCBMO0TQehMBNFGUo88bswVJ', 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}, id='run-a38cc231-c289-489b-9913-3d9ceabed38d-0', usage_metadata={'input_tokens': 20, 'output_tokens': 5, 'total_tokens': 25, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PARSERS\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "parser=StrOutputParser()\n",
    "final_prompt = prompt.invoke({\"language\":\"hindi\",\"text\":\"HOW ARE YOU?\"})\n",
    "op = model.invoke(final_prompt)\n",
    "op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ed5e1c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'आप कैसे हैं?'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser.invoke(op)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56ae1d4",
   "metadata": {},
   "source": [
    "## Chain\n",
    "- a static sequence of execution involving multiple components such as LLMs, parsers, prompts, tools, loaders etc.\n",
    "- can be used to automate a rule based, linear and non linear workflows involving LLMs, tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e906c76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'நன்றி'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translation_chain = prompt | model | parser\n",
    "translation_chain.invoke({\"language\":'tamil','text':'Thank You'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec849054",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_output(text):\n",
    "    return {\"Translation\":text}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f85d0a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Translation': 'நன்றி'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translation_chain = prompt | model | parser | format_output\n",
    "translation_chain.invoke({\"language\":'tamil','text':'Thank You'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46931d08",
   "metadata": {},
   "source": [
    "#### Code Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a09201f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```python\n",
      "def fibonacci(n):\n",
      "    fib_series = []\n",
      "    a, b = 0, 1\n",
      "    for _ in range(n):\n",
      "        fib_series.append(a)\n",
      "        a, b = b, a + b\n",
      "    return fib_series\n",
      "\n",
      "n = int(input(\"Enter the number of terms: \"))\n",
      "print(fibonacci(n))\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "generate_prompt = ChatPromptTemplate.from_template(\"Write a python code for {task}, Only provide python code, NO any additional text\")\n",
    "\n",
    "chain1 = generate_prompt | model | parser\n",
    "\n",
    "op = chain1.invoke({\"task\":\"fibonacci series\"})\n",
    "print(op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f5a9b78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_prompt = ChatPromptTemplate.from_template(\"Analyze the provided code and calculate time complexity {code}\")\n",
    "chain2 = analyze_prompt | model | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d0e13b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```python\n",
      "def fibonacci(n):\n",
      "    fib_series = [0, 1]\n",
      "    for i in range(2, n):\n",
      "        next_value = fib_series[-1] + fib_series[-2]\n",
      "        fib_series.append(next_value)\n",
      "    return fib_series[:n]\n",
      "\n",
      "# Example usage\n",
      "n = 10\n",
      "print(fibonacci(n))\n",
      "```\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Let's analyze the provided `fibonacci` function step-by-step to determine its time complexity.\\n\\n### Code Analysis\\nThe function `fibonacci(n)` generates the Fibonacci series up to the `n`-th term. Here's a breakdown of what the function does:\\n\\n1. **Initialization**: It starts by creating a list `fib_series` containing the first two Fibonacci numbers: `[0, 1]`.\\n\\n2. **Loop to Calculate Fibonacci Numbers**: The `for` loop runs from `2` to `n-1` (inclusive), meaning it executes `n-2` iterations (for an input of `n`, this means it calculates `n-2` additional Fibonacci numbers beyond the initial two).\\n\\n3. **Fibonacci Calculation**:\\n   - In each iteration of the loop, it calculates the next Fibonacci value by summing the last two values in the `fib_series` list (i.e., `fib_series[-1]` and `fib_series[-2]`).\\n   - After calculating the next Fibonacci value, it appends this value to the `fib_series` list.\\n\\n4. **Slicing the List**: Finally, it returns a slice of the first `n` Fibonacci numbers.\\n\\n### Time Complexity\\n\\nTo analyze the time complexity:\\n\\n- The loop runs `n - 2` times (or `O(n)` where `n` is the input size).\\n- Inside the loop, calculating the sum of `fib_series[-1]` and `fib_series[-2]` takes constant time `O(1)`.\\n- The list `append` operation in Python is also amortized `O(1)`.\\n\\nTherefore, each iteration of the for loop takes constant time, and since the loop runs `n - 2` times, the overall time complexity is:\\n\\n\\\\[ O(n) \\\\]\\n\\n### Space Complexity\\n\\nIn addition to time complexity, we can also consider the space complexity:\\n\\n- The space required is primarily for the `fib_series` list, which ultimately stores `n` Fibonacci numbers, leading to a space complexity of:\\n\\n\\\\[ O(n) \\\\]\\n\\n### Conclusion\\n\\nIn summary:\\n- **Time Complexity**: \\\\( O(n) \\\\)\\n- **Space Complexity**: \\\\( O(n) \\\\)\\n\\nThis means that both the time taken to compute the Fibonacci numbers and the space used to store them scale linearly with the input size `n`.\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def patch_response(code):\n",
    "    print(code)\n",
    "    print (\"-\"*20)\n",
    "    return {\"code\":code}\n",
    "\n",
    "\n",
    "final_chain = chain1 | patch_response | chain2\n",
    "\n",
    "op = final_chain.invoke({\"task\":'fibonacci series'})\n",
    "print(op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d8a89de4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```python\n",
      "number = int(input(\"Enter a number: \"))\n",
      "if number % 2 == 0:\n",
      "    print(\"Even\")\n",
      "else:\n",
      "    print(\"Odd\")\n",
      "```\n",
      "--------------------\n",
      "The provided Python code takes an integer input from the user and then checks whether that integer is even or odd by using the modulo operation. Here’s a breakdown of the code and its corresponding time complexity:\n",
      "\n",
      "### Code Analysis:\n",
      "\n",
      "1. `number = int(input(\"Enter a number: \"))`\n",
      "   - This line takes input from the user and converts it into an integer. The time taken for this line is O(1) since reading input and converting it to an integer do not depend on the size of the input; they are constant time operations.\n",
      "\n",
      "2. `if number % 2 == 0:`\n",
      "   - This line performs a modulo operation on the input number. The modulo operation itself is also O(1) in time complexity, as it is a basic arithmetic operation and does not depend on the size of the input.\n",
      "\n",
      "3. `print(\"Even\")` and `print(\"Odd\")`\n",
      "   - These lines print either \"Even\" or \"Odd\" based on the result of the modulo check. Each of these `print` statements has a constant time complexity of O(1).\n",
      "\n",
      "### Overall Time Complexity:\n",
      "\n",
      "Since all the steps are O(1) and occur sequentially, we can say that the overall time complexity of this code is:\n",
      "\n",
      "**O(1)**\n",
      "\n",
      "This means that the time taken to execute this code is constant and does not change with the size of the input number. Regardless of whether the input is small or large, the number of operations remains the same.\n"
     ]
    }
   ],
   "source": [
    "final_chain = generate_prompt | model | parser | patch_response | analyze_prompt | model | parser\n",
    "op = final_chain.invoke({\"task\":\"testing whether the number input is odd or even\"})\n",
    "print(op)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef25f20",
   "metadata": {},
   "source": [
    "### Tools in chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e65e9ab9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Page: Artificial intelligence\\nSummary: Artificial intelligence (AI) refers to the capability of computational systems to perform tasks typically associated with human intelligence, such as learning, reasoning, problem-solving, perception, and decision-making. It is a field of research in computer science that develops and studies methods and software that enable machines to perceive their environment and use learning and intelligence to take actions that maximize their chances of achieving defined goals. Such machines may be called AIs.\\nHigh-profile applications of AI include advanced web search engines (e.g., Google Search); recommendation systems (used by YouTube, Amazon, and Netflix); virtual assistants (e.g., Google Assistant, Siri, and Alexa); autonomous vehicles (e.g., Waymo); generative and creative tools (e.g., ChatGPT and AI art); and superhuman play and analysis in strategy games (e.g., chess and Go). However, many AI applications are not perceived as AI: \"A lot of cutting edge AI has filtered into general applications, often without being called AI because once something becomes useful enough and common enough it\\'s not labeled AI anymore.\"\\nVarious subfields of AI research are centered around particular goals and the use of particular tools. The traditional goals of AI research include learning, reasoning, knowledge representation, planning, natural language processing, perception, and support for robotics. General intelligence—the ability to complete any task performed by a human on an at least equal level—is among the field\\'s long-term goals. To reach these goals, AI researchers have adapted and integrated a wide range of techniques, including search and mathematical optimization, formal logic, artificial neural networks, and methods based on statistics, operations research, and economics. AI also draws upon psychology, linguistics, philosophy, neuroscience, and other fields.\\nArtificial intelligence was founded as an academic discipline in 1956, and the '"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "\n",
    "wikiapi = WikipediaAPIWrapper(top_k_results=1,lang='en',doc_content_chars_max=2000)\n",
    "tool = WikipediaQueryRun(api_wrapper=wikiapi)\n",
    "\n",
    "tool.invoke(\"Artificial Intelligence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a5a46af8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wikipedia\n",
      "A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.\n",
      "{'query': {'description': 'query to look up on wikipedia', 'title': 'Query', 'type': 'string'}}\n"
     ]
    }
   ],
   "source": [
    "print(tool.name)\n",
    "print(tool.description)\n",
    "print(tool.args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0962ed00",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_prompt = ChatPromptTemplate.from_template(\"Generate a query to be searched on wikipedia for the user question: {qus} keep it one word or phrase\")\n",
    "\n",
    "chain = search_prompt | model | parser | tool | parser\n",
    "chain.invoke({\"qus\":\"Tell me more about Latvia\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1747e43e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To search Wikipedia for information about Ukraine, you can use the following query:\n",
      "\n",
      "**\"Ukraine\"** \n",
      "\n",
      "You can simply type this term into the Wikipedia search bar, and it will direct you to the main article about Ukraine, where you will find comprehensive information on its history, geography, culture, and more. If you're looking for specific aspects, you can refine your search with additional keywords, such as \"Ukraine history,\" \"Ukraine geography,\" or \"Ukraine culture.\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Page: Havana Plan Piloto\\nSummary: The Havana Plan Piloto was a 1955–1958 urban proposal by Town Planning Associates, which included Paul Lester Wiener, Paul Schulz, the Catalan architect Josep Lluis Sert, and Seely Stevenson of Value & Knecht, Consulting Engineers, seeking to combine \"architecture, planning, and law\". The Charter got its name from the location of the fourth CIAM conference in 1933, which, due to the deteriorating political situation in Russia, took place on the \"in SS Patris II\" bound for Athens from Marseille. This conference is documented in a film commissioned by Sigfried Giedion and made by his friend László Moholy-Nagy. The Charter had a significant impact on urban planning after World War II and, through Josep Lluis Sert and Paul Lester Wiener, on the proposed modernization of Havana and in an effort to erase all vestiges of the 16th-century city. The plan was abandoned and was not made.'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def format_wiki(topic):\n",
    "    print(topic)\n",
    "    return topic\n",
    "\n",
    "chain = search_prompt | model | parser | format_wiki | tool | parser\n",
    "chain.invoke({\"qus\":\"Tell me more about Ukraine\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16fcdae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gen-ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
